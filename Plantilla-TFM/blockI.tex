
This block defines the vehicle routing problem and some methods to solve it to optimal.

\section{History of operational research}
Operational research, OR, deals with the application of advanced analytical methods to help make better decisions. % The operational research originated the efforts of military planners during Wold War I. 

The roots of OR can be traced back many decades, when early attempts were made
to use a scientific approach in the management of organizations. However, the beginning
of the activity called operations research has generally been attributed to the military services
early in World War II. Because of the war effort, there was an urgent need to allocate
scarce resources to the various military operations and to the activities within each
operation in an effective manner. During this time, in United Kingdom the need to study tactical and strategic problems associated with the defense of the country took a important role. In order to face this problems, the British government created interdisciplinary teams,
with the aim of solving these problems. These groups were called the operations research teams. United States, after observing the good results of the United Kingdom, begins to carry out similar studies, apart from the initial military and industrial applications, they include problems of complex logistics, planning of landmines at sea, effective use of
electronic equipment, etc. Due to the development of effective methods to use
the new tool that represented the radar, the scientists contributed
to the triumph in the air war waged by Great Britain. The research for
improving the management of antisubmarine and protection operations played an important role in the victory of the North Atlantic campaign.
Similar efforts were very helpful in the campaign of the Pacific. By the end of the 
war, the success of OR in the war activities generated great interest
due to the possibility of applying it in different fields than the military one. Operational research teams still work as usual facing industrial problem and getting important advancements in the state of the art resulted. A prime example is the simplex method for solving linear programming problems, developed by George Dantzig in 1947. Many of the standard tools of OR, such as linear programming, dynamic programming, queuing theory, and inventory theory, were relatively well developed before
the end of the 1947s. Later on, the computer development allowed the OR to grow, because solving complex problems involves several calculations. The use of the computer allows to take good and precision decisions quickly.

Nowadays, OR has many applications such as: military, industrial, sanity, financial, urban planning, transport system, etc. OR can be defined as the application of the scientific method to solve control organizational systems which aims to find solutions which improve objectives. 

One way of summarizing the usual (overlapping) phases of an OR study is the following:
\begin{enumerate}
	\item Define the problem of interest and gather relevant data.
	\item Formulate a mathematical model to represent the problem.
	\item Develop a computer-based procedure for deriving solutions to the problem from the
	model.
	\item Test the model and refine it as needed.
	\item Prepare for the ongoing application of the model as prescribed by management.
	\item Implement.
\end{enumerate}

The second point allows to abstract the essential elements of the problem in order to look for a solution which accords with the the goals. Furthermore, this procedure help the decision maker to find a good solution based on a mathematical method instead of using intuition.

To represent a problem by a OR model the following sets are usually needed:
\begin{itemize}
	\item Variables, whose values must be found.
	\item Objective function, which defines the effectiveness of the system by a mathematical function depending of the variables.
	\item Constraints, which limit the values of the variables to a feasible region.
	\item Parameters, which relate variables, constraints and objective function. They can be deterministic or probabilistic.
\end{itemize}

After a mathematical model is formulated for the problem under consideration, the next
phase in an OR study is to develop a procedure (usually a computer-based procedure) for
deriving solutions to the problem from this model. 



\section{Routing problem}
The study of the decision in the field of logistics is a very active area in operational research. Transport problems are of increasing importance as industry and service activities grow. 

Computational and mathematical methods to find optimal or near optimal routes could represent savings. Thus companies are interested in developing applications which automate routes design in order to minimize their cost. Transportation management can be usually defined by a pattern where a centralized fleet of vehicles distributes goods from a depot to a set of customers in different locations. As the number of customers, vehicles, deliveries or goods grow, finding a good routing configuration turns into a difficult task.

In this field, the route planning it is a key point that, from a mathematical point of view, is a complex problem and pretty difficult to solve exactly. 
%Thus, many heuristic algorithms focus on its resolution based on its combinatorial characteristic. 
This section is focused on vehicle routing problems, VRP, is a combinatorial optimization and integer programming problem. It was first defined by George Dantzig and John Ramser in 1959. This type of problem is a generalization of the traveling salesman problem, TSP, which can be framed within the framework of combinatorial and integer programming. The TSP receives this name because it can be described in terms of a sales agent, who must visit a certain number of cities in one trip. If the agent starts from its city of residence, must determine which route should follow to visit each city exactly once before returning home. The route must minimizes the total length of the trip. This problem gets complicated quickly as the number of cities increases. In the case of a problem with $n$ cities and arcs between each pair of them, the number of feasible routes that must be considered is $\frac{n-1}{2}$, since there are $(n-1)!$ possibilities to choose the first city, $(n-2)!$ for the next city, and so on. The denominator 2 arises because each route has one way equivalent inverse with the same distance. To address this problem algorithms based on the ramification and boundary approach are very effective. However, due to the difficulty to solve large problems of this type, heuristic methods guided by metaheuristic are a popular way to face these problems. Usually, these heuristic methods involve the generation of a sequence of feasible test solutions, where each new solution is obtained by improving the previous one.

Returning to the routing problem, 
The solution of a routing problem answers the question ''What is the optimal set of routes for a fleet of vehicles to traverse in order to deliver to a given set of customers?''
The problem requires the delivery of a certain product, stored in a single location,
to customers who have a certain demand. The main objective is to minimize the
total cost of traced routes. In 1964, Clarke and Wright improved the Dantzig and Ramser's approach using a greedy algorithm known as saving algorithm. Determining the optimal solution to VRP is NP-hard, of combinatorial optimization. It should also be noted that, the objective function of
a VRP can be very different depending on the particular application of the results. The most common objectives are: minimize the total cost of transportation based on the total distance traveled with the vehicles needed, minimize the number of vehicles, minimize the variation between travel time and
loading the vehicle, minimizing penalties for poor quality service, etc. Furthermore several variations and specializations of the vehicle routing problem exist:

\begin{itemize}
	\item Vehicle Routing Problem with Pick up and Delivery (VRPPD): A number of goods need to be moved from certain pick up locations to other delivery locations. The goal is to find optimal routes for a fleet of vehicles to visit the pick up and drop-off locations.
	\item Vehicle Routing Problem with LIFO: Similar to the VRPPD, except an additional restriction is placed on the loading of the vehicles: at any delivery location, the item being delivered must be the item most recently picked up. This scheme reduces the loading and unloading times at delivery locations because there is no need to temporarily unload items other than the ones that should be dropped off.
	\item Vehicle Routing Problem with Time Windows (CVRPTW): The delivery locations have time windows within which the deliveries (or visits) must be made.
	\item Capacitate Vehicle Routing Problem: CVRP or CVRPTW. The vehicles have limited carrying capacity of the goods that must be delivered.
	\item Vehicle Routing Problem with Multiple Trips (VRPMT): The vehicles can do more than one route.
	\item Open Vehicle Routing Problem (OVRP): Vehicles are not required to return to the depot.
\end{itemize}

The most common methods to solve the VRP are:

\begin{itemize}
	\item Use exact methods. The solution obtained by this methods is optimal but pretty hard to obtain.
	\item Constructive algorithms (as ant colony): they are techniques which construct solution taking into account the information obtained during the search process and the local information.
	\item Evolution algorithms (as genetic algorithm): these techniques explore the solution's space combining and modifying previous solutions. Thus, a set of solutions is modified to get a new of solutions which usually has a better result.
	\item Search algorithms (as tabu search): this type of algorithms start from an initial solution to improve based on some criteria. 
\end{itemize}


This Master thesis faces the vehicle routing problem with time windows. The objective of the VRPTW is to supply a number of customers within predefined time windows at minimum cost (commonly, in terms of traveled distance), respecting capacity constraints for each vehicle of an homogeneous fleet, i.e., given a number of customers with demands and time to be visited and an homogeneous fleet with capacities, the VRPTW consists of finding a configuration of routes starting and ending at a depot visiting every customer once in time. Each customer specifies the earliest and latest time for the start of the service and this requirement defines time window constraints.

A standard objective of the VRPTW aims to minimize the number of routes or vehicles, primary criterion, and the total travel costs, secondary criterion. However, other objective functions have been considered in various papers.
The VRPTW is non-polynomial-hard, NP-complete, (\cite{Lenstra}), thus 100 customers instances are hard to solve to optimality. Indeed, very few of the Solomon benchmark instances (\cite{Solomon_1987}) involving 100 customers have been solved optimally (\cite{Fisher}).
As a consequence, heuristic or metaheuristic algorithms, such as local or tabu search, genetic algorithms, evolutionary algorithms and ant colony optimization algorithms can offer a good approach to the problem. This Master thesis proposes a metaheuristic which combines randomized 2-optimization insertion and swapping algorithms for this transportation problem. Moreover, it provides experimental results that prove the effectiveness of the new metaheuristic.

The Block I is organized as follows. Section \ref{review} contains a review of the most relevant work in the VRP and gives an overview of the methodological approach. Section \ref{problem_formulation} defines the problem formulation. Section \ref{problem_formulation} presents the proposed metaheuristic, detailing each of its phases and the two different initial solutions considered. Section \ref{results} shows the experimental results obtained by testing the metaheuristic with two different problems: a set of classical VRPTW instances with heterogeneous fleet and capacity problem (\cite{Solomon_1987}) and a real agricultural cooperative VRPTW. Furthermore, section \ref{Robustness} analyses the robustness of the algorithm. Finally, section \ref{optimization_conclusion} concludes the paper and the appendix contains the improvements found on the Solomon benchmark.

\section{Literature review and methodological approach}\label{review}
Very different approaches has been tested into VRP. In this way, one can find classic methods such as saving algorithms (\cite{Clark}), or insertion heuristics (\cite{Solomon_1987}). Furthermore, a good heuristic algorithm for the traveling-salesman problem can be found at \cite{L-K}. This algorithm has been modified and implemented in \cite{Helsgaun}. Moreover, an interesting combination between clustering and local search can be found in \cite{ambro}.

The VRPTW has been addressed with a wide variety of approaches during last decades. Last years, local search techniques have been turned into metaheuristics. These include simulated annealing (\cite{Chiang}, \cite{Czech}, \cite{Balbina} and \cite{Woch}), tabu search (\cite{Backer}, \cite{Chiang2}, \cite{Cordeau}, \cite{Rochat} and \cite{Taillard}), genetic or evolutionary algorithms (\cite{Gehring}, \cite{bra3} and \cite{Potvin1996}), ant colony search (\cite{Gambardella}), large neighborhood search (\cite{Shaw1} and \cite{Shaw2}) and variable neighborhood search (\cite{Rousseau}). A different work can be found in \cite{Juan} where the VRP is faced using the biased randomization and iterative local search.

Some best known solutions for the Solomon benchmark have been found by a genetic algorithm (\cite{Berger}, \cite{bra} and \cite{bra2}) two-stage hybrid local search (\cite{Bent}) or by probabilistic diversification and intensification in local search (\cite{Rochat}). Some of these work focus on developing heuristics to find solutions quickly, while others focus on metaheuristics.

Considering these results and taking into account the VRPTW's computation complexity, this Master thesis introduces a probabilistic parameter into a metaheuristic algorithm to guide the local search process during the solution generation. The proposed metaheuristic is started at two different initial solutions, one of them can be considered a dummy solution, while the other one has a better routing configuration. To create the elaborated initial solution, a clustering algorithm is used to group the customers by location and later a modification of the Solomon algorithm \cite{Solomon_1987} is run to create routes at each cluster. Once an initial solution is created, the proposed metaheuristic improves it by moves, which combine 2-opt swaps at routes to minimize distance with inserting and swaps moves between routes in order to minimize the number of routes. These moves define a local search where such moves are chosen by a probabilistic parameter, $\beta.$ The proposed metaheuristic includes some techniques or data used in (\cite{Balbina}, \cite{Helsgaun}, \cite{Juan}, \cite{L-K} and \cite{Solomon_1987}). Moreover, it was tested with the Solomon benchmark and with a real agricultural problem which aims to minimize its transportation costs. 


\section{Problem formulation}\label{problem_formulation}
The VRPTW is defined by a graph $G=( V, A)$, where $V=\{0,1,\dots,n\}$ is a set of $n+1$ nodes and $A$ is the set of arcs. The depot is usually noted by node $0$ and customers are represented by remaining nodes, $V^{'} = V \setminus \{0\}$. Each customer $i \in V^{'}$ has a service time, $s_{i}$, and demands an amount of product, $d_{i}$, which must be served visiting each customer once. Travel cost between nodes $i$ and $j$ is denoted by $c(i,j)$, $i,j \in V $. $M$ identical vehicles with capacity, $Q$, are considered to supply customer's demand.

Each vehicle can describe a route, which starts at the depot, visits at least one customer and finishes at the depot. The customers visited by a route $r$ are noted by $cust(r)$. A route is noted by $r=(v_{0},v_{1},\dots,v_{|r|},v_{|r|+1})$ , $ v_{i} \in cust(r) \subseteq V^{'} $, $i = 1, \dots, |r|$, where $|r| = |cust(r)|$ denotes its size and $v_{0} = v_{|r|+1}$ denotes the depot. Observe that visited customers of a route are noted by $v_i$ instead of $i$ because this notation allows to sort the order in which customers are visited. That is, the $i-th$ visited customer by a route is represented by $v_i$. Hence, in the following, $v_i \in cust(r) \subseteq  V^{'}$, $i = 1, \dots, |r|,$ will note a visited customer while $u \in V^{'}$ will note an unrouted customer. Observe that a route is not empty if $|r|\geq 1$. Each route, r, will load the weight demands of its assigned customers, $q(r) = \sum_{i \in cust(r)} d_{i}$, thus each route has to respect the vehicles' capacity, that is $q(r) \leq Q$.

The travel cost of a route $r = (v_{0},v_{1},\dots,v_{|r|},v_{|r|+1})$, denoted by $t(r)$, can be computed in terms of the cost of visiting all of its customers, i.e., $t(r) = c(v_{0},v_{1})+ c(v_{1},v_{2})+ \dots + c(v_{|r|-1},v_{|r|}) + c(v_{|r|},v_{|r|+1})$.

Each customer $ i \in V^{'}$ has an early time, $e_{i},$ and a late time, $l_{i} $. Vehicles must arrive at nodes before its late time. They may arrive before its early time, but they have to wait until $e_{i}, i \in V^{'}$, to start the service. Note that $e_{0},$ represents the initial time when routes can start and $l_{0}$ represents the maximum time when routes can return to the depot. No route can arrive at depot after $l_{0}$, thus it can be said that depot's late time introduces a distance or time constraint. %Observe that most papers assume that $l_{0}=0$.


A routing configuration is a set of routes $R=\{r_{1},r_{2},\dots,r_{m} \}$, where $m \leq M$, which visits every customer exactly once and that satisfies time window and capacity constraints. In this way, the routing configuration is a solution to the VRPTW. 

The VRPTW has a hierarchical objective which, firstly, minimizes the number of routes and, second, minimizes the total distance.

\section{Proposed metaheuristic}\label{proposed_metaheuristic}

This section explains the proposed metaheuristic in detail. In this way, subsection \ref{initialsol} explains how to construct two different initial solutions. Subsections \ref{MovesInsideRoutes} and \ref{MovesDifferentRoutes} detail the local searches defined by 2-opt, inserting and swapping moves. Finally, subsection \ref{Mainalgorithm} presents the metaheuristic which guides and unifies the local searches by a probabilistic parameter $\beta$.

\subsection{Initial solutions}\label{initialsol}

As mentioned in section \ref{review}, the metaheuristic starts at an initial solution, thus two procedures are designed to obtain different solutions. One of them gives a simple solution which in the following will be called dummy solution. The second procedure returns a better routing configuration which, in the following, will be called elaborated solution. To create the elaborated initial solution, a clustering algorithm is used to group the customers by location and later a modification of the Solomon algorithm is run to create routes at each cluster.

The metaheuristic can be started at a dummy solution in which all of its routes start at the depot, visit one customer and finish at the depot. In other words, let $G=(V,A)$ define a VRPTW, a dummy solution is defined by a set of routes, $\{r_{1},r_{2},\dots,r_{m} \}$, where $m \in \mathbb{N}$, $ m = n$, such that $\forall i \in V^{'}, \exists m^{'} \text{with } 1\leq m^{'}\leq m, r_{ m^{'}}=(v_{0},i,v_{0})$. Observe that a dummy solution has as many routes as customers. Furthermore, if a dummy solution does not respect capacity or time window constraints the problem has no feasible solution. %If the dummy solution defines a routing configuration then the algorithm can be started.

In order to construct an elaborated initial solution, the customers are grouped by their location. This agroupation is made by the so-called K-means clustering method (\cite{cluster}), which is an unsupervised learning algorithm that tries to cluster data based on their similarity. This method requires the numbers of clusters to be given. Once customers are clustered by their location, a modification of the Solomon insertion algorithm is applied to supply all customers of each cluster by one route. If constraints do not allow this solution to be feasible, then the number of clusters is increased. The well known Solomon algorithm introduces an insertion criteria which represents the suitability of inserting a customer into any position of a route. Solomon measures this suitability by the saving, starting time of service and late time of the insertion. This criteria are weighted and represented by the quantity noted by $S^{'}(v_i,u,v_{i+1}),$ $i=0, \dots, |r|+1$, $v_{i}, v_{i+1}\in V,$ $u \in V^{'}$, where $v_{i},v_{i+1}$ denote the depot or visited customers of the route. $u$ is an unrouted customer which could be inserted between $v_i$ and $v_{i+1}$. In order to detail the computation of $S^{'}$ the following concepts must be introduced. Given a route $r$, $b(v_{i+1})$ notes the starting time of service at customer $v_{i+1}$, $v_{i+1} \in cust(r)$. $b(v_{i+1},u)$ notes the new starting time for the service at a customer $v_{i+1}$, once an unrouted customer $u$, $u\in V^{'}$ is inserted in the route $r$ before $v_{i+1}$. Then, given a route $r = (v_{0},v_{1}, \dots, v_{i}, v_{i+1}, \dots,v_{|r|},v_{|r|+1} ) $ and an unrouted customer $u$, $u\in V^{'}$, the suitability of inserting $u$ between $v_{i},v_{i+1}$ is computed by $S^{'}(v_{i},u,v_{i+1})$:

$S^{'}(v_{i},u,v_{i+1}) = \alpha_{1}*Sc_{1}(v_{i+1},u,v_{i+1}) + \alpha_{2}*Sc_{2}(v_{i},u,v_{i+1}) + \alpha_{3}*Sc_{3}(v_{i},u,v_{i+1})$,

where:

$Sc_{1}(v_{i},u,v_{i+1})  = c(v_{i},u) +  c(u,v_{i+1})  - \lambda* c(v_{i},v_{i+1})$ , $\lambda \geq 0$

$Sc_{2}(v_{i},u,v_{i+1})  = b(v_{i+1},u) -  b(v_{i+1})  $

$Sc_{3}(v_{i},u,v_{i+1})  = l(u) -  b(u) $

$ \alpha_{1}+\alpha_{2}+ \alpha_{3}=1$,  $\alpha_{i} \geq 0$, $i=1,2,3$

$Sc_{1}$ represents the cost of inserting customer $u$ between $v_{i}$ and $v_{i+1}$ and $\lambda$ weights the distance between $v_{i}$ and $ v_{i+1}$. $Sc_{2}$ gives the difference of the service time at customer $v_{i+1}$ when $u$ is inserted. $Sc_{3}$ shows the difference of the service time and latest time of arrival of customer $u$. To weight each criteria, parameters $ \alpha_{1},\alpha_{2}$ and $\alpha_{3}$ are introduced. The best insertion position of customer $u$ is computed by $S(u)= min \{ S^{'}(v_{i},u,v_{i+1}) , i= 0, \dots, |r| \}$. Once best insertion places are computed for all unrouted customers, Solomon algorithm chooses the best insertion candidate as the candidate which minimizes $S$, i.e., $candidate = \{u \text{ }| \text{ }S(u) = min\{S(u^{'} ), \text{ for all unrouted customers } u^{'} \} \}$. 

Solomon's algorithm has shown good results, but the developed procedure chooses the insertion candidate by a little modification because it computes initial solutions, which are made to be improved, therefore getting them rapidly is more important than the distance they present. In order to introduce this consideration, the proposed approach chooses the best insertion candidate by $candidate =\{u \text{ } | \text{ } S^{'}(v_{i},u,v_{i+1}) =  min \{ S^{'}(v_{i},u^{'},v_{i+1}) , i= 0, \dots, |r|, \text{ for all unrouted customer } u^{'} \}\}$, which implies that the modification considers all positions for every unrouted customer while Solomon's algorithm selects candidates from a list of the best insertion place for each customer. As one can see, the developed algorithm includes the Solomon criteria: $Sc_{1}$, $Sc_{2}$ and $Sc_{3}$ but, it presents a simpler way to select candidates. 

Moreover Solomon's algorithm involves some computations in order to find the best insertion place for each unrouted customer, while the developed procedure avoid them by choosing the candidate which minimizes $S^{'}(v_{i},u,v_{i+1})$. This simplification makes the proposed modification quicker than the Solomon's algorithm. Note that, if cost function does not respect triangle inequality or $\lambda \geq 1$, Solomon algorithm can insert a customer $u$ between customers $v_{i}, v_{i+1}$ where $ Sc_{1}(v_i, u, v_{i+1}) < 0$. Another modification is that the proposed procedure does not allow negative insertions because it aims to minimize the distance as a second criteria. It must be underlined that the routing configuration made by just allowing positive insertions may have more routes than a configuration made by admitting negative insertions. Nevertheless, recall that this procedure constructs an initial solution, thus it does not have to create a routing configuration with the minimum number of routes. It just seeks to construct an initial solution with less routes and distance than a dummy solution. 


In order to create the elaborated initial solution two algorithms \ref{algoritmoCluser} and \ref{Solomon} were developed. Algorithm \ref{algoritmoCluser} unifies the K-means algorithm with the modified Solomon insertion algorithm \ref{Solomon}. It starts the number of cluster at 1 and call the modified Solomon insertion algorithm. If constraints do not allow to create a routing configuration with one route, the number of cluster is increased until a routing configuration which visits all customers of each cluster by one route is found.


On the other hand, algorithm \ref{Solomon} starts as many routes as the current number of clusters and assigns a route to each cluster. The starting routes are empty, i.e., they do not visit any customer and start and end at the depot. Moreover the algorithm selects a cluster and creates a matrix, $M$, to summarize the relevant information referring to the suitability of every possible insertion of the current cluster. When the algorithm chooses a different cluster, then it removes $M$ to create a new one with the information of the new cluster. A row of $M$ has the following structure $(v_i,u, v_{i+1},$ $ S^{'}(v_i, u, v_{i+1}), Sc_{1}(v_i, u, v_{i+1}))$. The matrix has five columns and as many rows as possible insertions for every unrouted customer exist. Moreover, $M(Sc_1)$ denotes the column of $M$ which contains the values of $Sc_1(v_i,u,v_i+1)$ for every possible insertion. Furthermore, the rows of the matrix are sorted by $S{'}$ in increasing order, thus the first row of $M$ represents the best insertion candidate while its last row represents the worst insertion candidate. In this way, the proposed modification of the Solomon algorithm chooses the first row of $M$ as candidate. Note that in this step candidate is a vector, thus candidate(u) will note the unrouted customer to be inserted. Once the routes are started, the algorithm tries to insert the customers of each cluster to the cluster's route taking the following steps:

\begin{framed}
	\begin{steps}{Step}
		\step Select an unrouted cluster and its route.
		\step Create $M$.
		\step Select the first row of $M$, which represents the best candidate.:
		\begin{steps}{Step 3}
			\step If the candidate respects constraints and $Sc_{1}(v_i, u, v_{i+1}) > 0$ then, insert $u$ in the route between $v_i$ and $v_{i+1}$. Repeat the Step 2 until all customers are inserted.
			\step If the candidate does not respect constraints remove it from $M$ and repeat the Step 3 until a customer is inserted or $M$ is empty.
			\step If $Sc_{1}(v_i, u, v_{i+1}) < 0$ the algorithm is stopped (number of clusters must be increased).
		\end{steps}
		\step Repeat the step 1 to an unrouted cluster until all clusters are routed or $M$ is empty or $max(Sc_{1}) < 0$ .
	\end{steps}
\end{framed}

After iterating this steps over all clusters, two situation can be performed: a routing configuration is found (thus an elaborated initial solution is constructed) or requirements do not allow to create a routing configuration (thus the number of cluster must be increased one unit).

The pseudo-codes of both elaborated initial solution and the modified Solomon's insertion algorithm can be found bellow (algorithm \ref{algoritmoCluser} and \ref{Solomon}) :

\begin{algorithm}[H]
	\caption{Modified\_Solomon\_algorithm(clustered\_customers,$\lambda,\alpha_{1},\alpha_{2},\alpha_{3}$)}
	\label{Solomon}
	\begin{algorithmic}[1]
		\STATE number\_routes $\leftarrow$ number\_clusters																	  
		\FOR{ $i$ in number\_clusters}
		\STATE unrouted$(i)$  $\leftarrow$  customers$(i)$
		\STATE route$(i)$  $\leftarrow$  c(0,0)
		\ENDFOR
		\FOR{ $i$ in number\_clusters}
		\WHILE{ unrouted$(i)$ is not empty and max( $M(Sc_{1})$) $>$ 0
		}
		\STATE  $M$ $\leftarrow$  $compute\_M$(unrouted($i$),route($i$),$\lambda,\alpha_{1},\alpha_{2},\alpha_{3} $)
		\WHILE{ max($M(Sc_{1})$) $>$ 0 and stop $\ne$ 1}
		\STATE candidate  $\leftarrow$ first\_row($M$)
		\IF{ candidate respects constraints}
		\STATE route$(i)$  $\leftarrow$ candidate
		\STATE remove candidate($u$) from unrouted$(i)$
		\STATE stop  $\leftarrow$ 1
		\ELSE
		\STATE remove candidate from $M$							
		\ENDIF			
		\ENDWHILE	
		\ENDWHILE	
		\ENDFOR
		\IF { all customers are visited}
		\STATE return(elaborated\_initial\_solution)
		\ELSE 
		\STATE return(number of cluster must be increased)
		\ENDIF		
	\end{algorithmic}
\end{algorithm}



\clearpage

\begin{algorithm}[H]
	\caption{Elaborated\_initial\_solution}
	\label{algoritmoCluser}
	\begin{algorithmic}[1]
		\STATE number\_clusters $\leftarrow$ 1																	  
		\STATE    clustered\_customers   $\leftarrow$ k-means(customers, number\_clusters)                                											  
		\WHILE{ elaborated\_initial\_solution is not obtained and number\_clusters $\leq$ number\_customers}
		\STATE   elaborated\_initial\_solution   $\leftarrow$ Modified\_Solomon\_algorithm(clustered\_customers,$\lambda,\alpha_{1},\alpha_{2},\alpha_{3}$)		      
		\STATE number\_clusters $\leftarrow$	number\_clusters + 1         	
		\ENDWHILE						  
		\IF{ elaborated\_initial\_solution is obtained}													  
		\STATE return(elaborated\_initial\_solution)																  
		\ELSE
		\STATE	return(problem is infeasible)		
		\ENDIF
	\end{algorithmic}
\end{algorithm}

\subsection{Exchange moves inside routes}\label{MovesInsideRoutes}

Once an initial solution is created, the proposed metaheuristic improves it by different moves: moves inside routes and moves between different routes. The implemented moves inside routes are inspired in the Lin-Kerninham algorithm. This section details this well known algorithm and explains a proposed modification.

Lin-Kerninham algorithm (\cite{L-K}) is one of the best heuristics for solving the symmetric traveling salesman problem. This algorithm is specified in terms of moves, or exchanges, that can transform a route into another with less distance. This algorithm is classified as a tour improvement algorithm, in particular, as the so-called 2-opt algorithm. The k-opt algorithm enhances a given tour by swapping $k$ nodes of the tour in such a way that the new tour's length is shorter. Usually, k-opt implementations set $k = 2$ or $k = 3$ because if $k>3$ the algorithm requires lot of calculus to get a small improvement of the solution. A small improvement does not justify that increase of running time. Tour's improvements are measured by the length, or the cost, of the tour which can be computed as the sum of the arcs which connects the nodes in the visiting order. That is, given a feasible tour $\tau=(0,\dots,v_{i}, v_{i+1}, v_{i+2}, v_{i+3},\dots,0)$,
%the algorithm repeatedly performs exchanges between consecutive nodes, i.e., given a route 
the 2-opt exchange of customers $v_{i+1}$ and $v_{i+2}$ changes $\tau$ to $\hat{\tau}$ as follows, $ \tau =(0,\dots,v_{i}, v_{i+1}, v_{i+2}, v_{i+3},\dots,0)$   $\rightarrow_{move}$  
$\hat{\tau}=(0,\dots,v_{i}, v_{i+2}, v_{i+1}, v_{i+3},\dots,0)$ and the distance, or the cost, of tour $\tau$ is computed by $c(\tau) = \sum_{i = 0}^{|\tau| } c(v_{i}, v_{i+1})$.  The difference of distance between tours $\tau$ and $\hat{\tau}$ produced by exchanging nodes $v_{i+1}$ and $v_{i+2}$ is computed by $\alpha(v_{i+1},v_{i+2}) = c(v_{i},v_{i+1}) + c(v_{i+2},v_{i+3} ) - c(v_{i},v_{i+2} )- c(v_{i+1},v_{i+3})$. Note that whether $\alpha(v_{i+1},v_{i+2})>0$ the move represents savings, but if $\alpha(v_{i},v_{j})<0$ the move represents losses. This exchange modifies the arcs which connect $v_{i}$ to $ v_{i+1} $ and $ v_{i+2}$ to $v_{i+3}$. This type of exchanges are represented in figure bellow (\ref{move1}).

\begin{figure}[H]
	\centering
	\scalebox{0.4}[0.4]{
		\includegraphics[width=\linewidth]{./img/lk1y2.jpg}
	}
	\caption{2-opt exchange.}
	\label{move1}
\end{figure}\

An implementation of the 2-opt algorithm usually perform exchanges until no saving moves can be done. In this way, this algorithm generates an initial tour, $\tau$, and performs exchanges to create new tours, $\hat{\tau}$, until $max(\alpha)<0$. When the algorithm ends the last created tour is the best found tour. A generalization of this simple principle forms the basis for the Lin-Kerninham algorithm. Lin and Kerninham realized that a 2-opt may stop at a local minimum because it does not allow negatives exchanges. In this way, if negatives exchanges are allowed to transform $\tau$ into $\hat{\tau}$ where the distance of $\hat{\tau}$ is bigger, i.e., $c(\tau) < c(\hat{\tau})$, and 2-opt moves are considered in $\hat{\tau}$, then a new tour $\hat{\tau}^{'}$ with shorter length than $\tau$ may be found. Moreover, Lin-Kerninham introduces a different stopping criteria. This algorithm does not allow to change moved arcs, in such a way, the algorithm will stop when every exchange involves moved arcs. The Lin-Kerninham algorithm can be implemented following the next steps:\\

%\fbox{%
%	\parbox{\textwidth\hspace{4pt}}{%
%		\begin{steps}{Step}
%			\step Generate a random initial tour, $\tau$, and set $j = 1$.

%	\begin{steps}{Step 2.}
%			\step Perform the best 2-opt exchanges of $\tau$ creating $\tau^{j}$ (even exchanges representing losses) and set $j = j + 1$.
%			\step Perform the best 2-opt exchanges of $\tau^{j-1}$ creating $\tau^{j}$ which does not modify created arcs at step 2.
%			\step	Repeat step 3 until exchanges cannot be performed.
%			\step Set $\tau^{'}$ such that $c(\tau^{'}) = min(c(\tau^{j}))$
%			\step If the distance of $\tau^{'} $ is smaller than the distance of $\tau$, then let $\tau = \tau^{'} $ and go to step 2.\\ If the distance of $\tau^{'}$ is greater or equal to the distance of $\tau$, then the algorithm ends. \label{step6}
%	\end{steps}


%		\end{steps}
%}}\\

Lets introduce the proposed modification of the algorithm, hereinafter referred to as exchange algorithm, after underlying that this modification will enhance routes instead of tours. Recall that the Lin-Kerninham algorithm was designed to solve traveling salesman problems, hence it is used to improve tours which do not have to respect VRPWT'S constraints. Capacity and time windows constraints may reduce the number of accomplished exchanges. That fact can guide the exchange algorithm to a local minimum, thus more moves must be considered. In this way, given a route, $r=(0,\dots,v_{i},\dots,v_{j},\dots,0)$, %of a routing configuration $\{r_{1},r_{2},\dots,r_{m}\}$, h  the algorithm will consider the 
the proposed modification considers the following exchanges:

$r=(v_{0},\dots,v_{i-1},v_{i},\dots,v_{j}, v_{j+1},\dots,v_{r+1})$ $\rightarrow_{move}$
$r^{'}=(v_{0},\dots,v_{i-1},v_{j},\dots,v_{i},v_{j+1},\dots,v_{r+1})$,

$\forall i = 1,\dots,|r| - 1$, $\forall j= i+1,\dots,|r| $.

That is, the algorithm can exchange any pair of customers visited by route $r$, while the original algorithm just considers to exchange consecutive customers of a route. Observe that the running time increases as the number of exchanges increase. Nerveless, the improvement of the solution by this modification justifies its small increasing of running time. Moving back to the traveling salesman problem, note that any move which does not involve modified arcs can be taken. However, the exchange algorithm chooses the best move and it checks whether the move can be taken. Therefore it can be said that the exchange algorithm chooses candidates. If the candidate respects the constraints the move is taken, otherwise the candidate will be rejected and the algorithm will select a different candidate. When a move is taken the route $r$ is transformed into a route $r^{'}$. In order to be able to select the best route, the exchange algorithm creates a list of improved routes.

The best candidate is the move which minimizes the cost of $r^{'}$. The difference of cost between routes $r$ and $r^{'}$ produced by exchanging nodes $v_{i}$ and $v_{j}$ is computed by $\alpha(v_{i},v_{j}) = c(v_{i-1},v_{i}) + c(v_{j},v_{j+1} ) - c(v_{i-1},v_{j} )- c(v_{i},v_{j+1})$. Note that whether $\alpha(v_{i},v_{j})>0$ the move represents savings, but if $\alpha(v_{i},v_{j})<0$ the move represents losses. Recall that the Lin-Kerninham algorithm chooses the best move, i.e., $max\{\alpha(v_{i},v_{j}), v_{i}, v_{j} \in \tau \} $ until no moves can be done, even moves representing losses. However, an implementation of the Lin-Kerninham algorithm which just considers saving moves has shown a quality outcome (\cite{Helsgaun}). Thus the exchange algorithm introduces this consideration. Moreover,the exchange algorithm incorporates a geometric biased distribution, $\beta$, to select candidates. The implemented randomization have been applied in \cite{Juan} showing good results. In this way, the exchange algorithm ends if no saving moves exist and candidates are chosen by a probabilistic parameter. 

To select a candidate, the exchange algorithm creates a matrix, $M$, whose columns represents, $v_i,v_j,$ $ \alpha(v_i,v_j)$ and whose dimension is $n \times 3$, where $n$ denotes number of possible moves. Once the matrix is sorted by $\alpha$ in decreasing order, its first row will represents the best move, while its last row will represents the worst one. The candidate will be selected from $M$ computing a value $m$, $m=\frac{\log(p)}{\log (1- \beta)}mod$ $n$, where $\beta  \in [0,1)$ and $p$ is a random number, $p \in (0,1]$. That is, setting a value of $\beta$ and randomly generating a value of $p$, $m$ will take a value in the interval $[1,n]$. After computing the value of $m$, the exchange algorithm considers the candidate as the move represented in the $m$ row of $M$. Note that since $p \in (0,1]$, if $\beta \rightarrow 1$ the algorithm will choose the best candidate and, if $\beta = 0$ the algorithm may choose one of the worst candidates. Furthermore, exchanges may represent losses if $\beta < 1$. Remember that the Lin-Kerninham algorithm does not allow moves which involves modified arcs, i.e, it does not allow to move exchanged nodes $v_{i}, v_{i+1},v_{i+2}, v_{i+3}$. This thought is a good approach but it may involve few iterations of the algorithm, which is not really a disadvantage when just the Lin-Kerninham algorithm is used to improve a tour. However, this Master thesis proposes a metaheuristic formed by three different local searches, thus each local search should have a good running time. The metaheuristic searches small improvements of the solutions at each iteration (subsection \ref{Mainalgorithm} details the main algorithm), thus each local search just needs to improve a given routing configuration,i.e., local searches do not try to find the optimal solutions. Furthermore, the exchange algorithm allows more moves than the Lin-Kerninham algorithm, which may need a different criteria to forbid moves. Hence, considering these ideas, the exchange algorithm does not allow to move exchanged nodes $v_i,v_j$ and it stops when no moves can be taken or the $max(M(\alpha))<0$.

To summaries, the exchange algorithm starts at an initial route, $r$, of a given routing configuration, computes the matrix $M$ and chooses a candidate by $m$. If the the candidate can be taken, its customers are exchanged transforming the route $r$ into a new route $r^{'}$. The algorithm inserts $v_i,v_j$ into a tabu list, $r^{'}$ into a list of improved routes and sets $r = r^{'}$. If the candidate cannot be taken, it is removed from $M$ and the algorithm selects other candidate recalculating $m$. The algorithm iterates over this logic until no moves can be taken, i.e., $max(M(\alpha))<0$ or the tabu list does not allow to exchange customers. 

When the algorithm meets these criteria, it chooses the best route, $ r^{'}$, from the list of improved routes and checks whether the cost of this route, $c( r^{'})$, is smaller than the cost of the initial route $c(r)$. If $c( r^{'}) < c(r)$, the initial route is setted as the best improved route and the algorithm starts again. Otherwise, the $r^{'}$ is not better than $ r$, thus the algorithm stops to improve the select route and selects a different one until all routes are analyses. %It must be underline that when the Lin-Kerninham algorithm's stopping criteria stops the algorithm, it sets the improved tour as the initial tour (see \ref{step6} of the algorithm). Nevertheless the proposed modification ends when the stopping criteria stops the iteration. The modification does not incorporate this step to find an improvement of a given solution instead of finding a nearly-optimal solution. However, one can see that iteratively executing the modification is equivalent to incorporate Step 6 to the modification.
The pseudo-code of the proposed modification is given bellow (algorithm \ref{opt}):


\begin{algorithm}[H]
\caption{exchange\_algorithm(initial\_routing\_configuration, $ \beta$ )}
\label{opt}
\begin{algorithmic}[1]
	\STATE routing configuration $\leftarrow$ initial routing configuration 																	  
	\FOR{ initial\_route in routing configuration}
	\WHILE{ stop\_route  $\ne$ 1 }
	\STATE route $\leftarrow$  initial\_route
	\WHILE{ stop\_iteration $\ne$ 1}
	\STATE compute $M$ 
	\WHILE{$max(M(\alpha))\geq 0$   and recalculate $\ne$ 1   }
	
	\STATE candidate  $\leftarrow$ compute\_m($\beta,p,n$)
	\IF{candidate respects constraints}
	\STATE route  $\leftarrow$  candidate 
	\STATE list\_improvements (route)  $\leftarrow$  route   
	\STATE recalculate $\leftarrow$ 1 
	\STATE tabu  $\leftarrow$    $(v_{i},v_{j})$  
	\ELSE 
	\STATE  remove candidate	from $M$
	\ENDIF
	\IF{ $max(M(\alpha))< 0$	or  length(tabu) $ \geq |r|-1$ }
	\STATE recalculate  $\leftarrow$ 1
	\STATE stop\_iteration  $\leftarrow$ 1
	\ENDIF
	\ENDWHILE
	\ENDWHILE
	
	\IF{ cost(best(list(route))) $\le$ cost(initial\_route) }
	\STATE initial\_route  $\leftarrow$ best(list(route))
	\STATE clear tabu	    
	\ELSE
	\STATE  stop\_route  $\leftarrow$ 1 
	\ENDIF
	\ENDWHILE
	\STATE routing configuration $\leftarrow$ initial\_route.
	\ENDFOR
	\STATE return(routing configuration) 
\end{algorithmic}

\end{algorithm}





\subsection{Inserting and swapping moves}\label{MovesDifferentRoutes}

This section details the moves between different routes which aim to minimize the number of routes and its cost. Given a routing configuration, $\{r_{1},r_{2},\dots,r_{m}\}$, the algorithm will consider, for each customer, two kind of movements: inserting and swapping changes. 
Inserting moves insert a customer $v_{i} \in r_{p}, p = 1,\dots,m-1$, into $r_{q}$ where $q=p+1,\dots,m$ as follows:

\begin{equation*}
\begin{rcases}
r_{p} &= (0,\dots,v_{i-1},v_{i},v_{i+1},\dots,0) \\
r_{q} &= (0,\dots,v_{j},v_{j+1},\dots,0)
\end{rcases}
\text{ $\rightarrow_{\text{inserting move}}$}	\begin{rcases}
r_{p} &= (0,\dots,v_{i-1},v_{i+1},\dots,0)\\
r_{q} &= (0,\dots,v_{j},v_{i},v_{j+1},\dots,0)
\end{rcases}
\end{equation*}
In other hand, swapping moves exchange a customers $v_i, v_j$ of different routes, that is, a swapping move can swap any customers $v_{i} \in r_{p}, p = 1,\dots,m-1$, $v_{j} \in r_{q}$ where $q= p + 1, \dots , m$  as follows:


\begin{equation*}
\begin{rcases}
r_{p} &= (0,\dots,v_{i-1},v_{i},v_{i+1},\dots,0)  \\
r_{q} &= (0,\dots,v_{j-1},v_{j},v_{j+1},\dots,0)
\end{rcases}
\text{ $\rightarrow_{swap}$}	\begin{rcases}
r_{p}^{'} &= (0,\dots,v_{i-1},v_{j},v_{i+1},\dots,0)  \\
r_{q}^{'} &= (0,\dots,v_{j-1},v_{i},v_{j+1},\dots,0)
\end{rcases}
\end{equation*}

Both inserting and swapping moves are represented by figure bellow (\ref{moves2}). This figure illustrates an example where a routing configuration is formed up by two routes $r_{1} = (0,3,4,0)$ and $r_{2} = (0,1,2,0)$. Letting $v_i = 2$ and $v_j = 4$. One can see at figure \ref{ExInsertingMove} that an inserting move can insert customer $4$ into $r_2$. On the other hand, figure \ref{ExSwappingMove} shows that a swapping move can swap these customers.

\begin{figure}[H]
\begin{subfigure}{.5\textwidth}
	\centering
	% include first image
	\includegraphics[width=.8\linewidth]{./img/join.jpg} 
	\caption{Inserting moves between different routes.}
	\label{ExInsertingMove}
\end{subfigure}
\begin{subfigure}{.5\textwidth}
	\centering
	% include second image
	\includegraphics[width=.8\linewidth]{./img/swap.jpg} 
	\caption{Swapping moves different routes.}
	\label{ExSwappingMove}
\end{subfigure}
\caption{Moves between different routes}
\label{moves2}
\end{figure}


Both inserting and swapping moves may change the total cost of the routes. The difference of cost between routes $r_{p},r_{q}$ and routes $r_{p}^{'},r_{q}^{'}$ produced by inserting a customer $v_i$ of $r_p$ between customers $v_j, v_{j+1}$ of $r_q$ is denoted by $\alpha$ and its computed as follows:
$\alpha(v_{i},v_{j}) = c(v_{i-1},v_{i}) + c(v_{i},v_{i+1}) + c(v_{j},v_{j+1}) -c (v_{i-1},v_{i+1}) -c (v_{j},v_{i})- c(v_{i},v_{j+1})$.

%Figure \ref{moves3} shows this type of moves.
On the other side, the cost difference produced by swapping a customer $v_i$ of the route $r_p$ with a customer $v_j$ of the route $r_q$ can be computed by
$\alpha(v_{i},v_{j}) = c(v_{i-1},v_{i}) + c(v_{i},v_{i+1}) + c(v_{j-1},v_{j})  + c(v_{j},v_{j+1}) 
-c (v_{i-1},v_{j}) -c (v_{j},v_{i+1})- c(v_{j-1},v_{i}) -  c(v_{i},v_{j+1})$.

To implement these movements, two algorithms were developed: an inserting algorithm and a swapping algorithm. These algorithms enhance a given routing configuration by moves until a stopping criteria is met. These moves must respect VRPTW's constraints, thus the algorithms select candidates from all possible moves and perform the best candidate which respects VRPTW's constraints, that is, the best move which can be taken. As explained in \ref{MovesInsideRoutes}, these algorithms create a matrix, $M$, whose rows represents every possible move between any route of the configuration route and they select candidates by the value $m$, with random components. The algorithms stop when the stopping criteria is met, $max(M(\alpha))<0$. The main difference between exchange algorithm and inserting and swapping algorithms is that the exchange algorithm computes exchanges between customers of a route while the inserting and swapping algorithms perform moves between different routes. Thus, the exchange algorithm improves the routing configuration by enhancing its routes one by one while the inserting and swapping algorithms perform a global improvement.

Furthermore, the inserting and swapping algorithms modify the initial routing configuration. Recall that a routing configuration is formed up by a set of routes, $\{r_{1},r_{2},\dots,r_{m}\}$. The number of customer of each route can differ. In this sense, trying to insert a customer into a route which visits lot of customers is not likely to succeed, because it may violate time windows constraints. Besides, trying to insert a customer into a route which visits a few customers likely to succeed, because it probably does not violate time windows constraints. This consideration suggests to order a routing configuration by the length of its routes. In this way, given a routing configuration, the algorithms sort it by decreasing order creating a new one whose first route is the one which visits more customers, while its last route is the shortest one, i.e., $|cust(r_1)| \geq |cust(r_2)| \geq  \dots \geq  |cust(r_m)|$. In this way, if the inserting algorithm tries to insert a customer of the first route into the last one by setting $p=1$ and $q=m$, it probably finds a feasible insertion. This sorting criteria may unify the number of customer of the routes. Nevertheless, a stander objective for the VRPTW is to minimize the number of routes, thus trying to insert customers of small routes into large routes may decrease the number of routes. This objective suggests that the configuration route must be order in increasing order i.e., $|cust(r_1)| \leq |cust(r_2)| \leq   \dots \leq |cust(r_m)|$. Regarding these ideas, the inserting algorithm can sort a given routing configuration by increasing order and decreasing order.

To summaries, the inserting and swapping algorithms start at given routing configuration and the inserting one sorts the configuration by a given order. The algorithms compute the matrix $M$ and choose a candidate by $m$. If the the candidate can be taken, its customers are exchanged transforming the routing configuration $R$ into a new routing configuration $R^{'}$. The algorithms insert $R^{'}$ into a list of improved routing configurations and sets $R = R^{'}$. If the candidate cannot be taken, it is removed from $M$ and the algorithms select another candidate recalculating $m$. The algorithms iterate over this logic until no moves can be taken, i.e., $max(M(\alpha))<0$. When the algorithms meet these criteria, they choose the best routing configuration, $R^{'}$, from the list of improved routing configurations. Then algorithms check whether the cost of this routing configuration, $c(R^{'})$, is smaller than the cost of the previous routing configuration, $c(R)$. If $c(R^{'}) < c(R)$, then $R$ is setted as $R^{'}$ and the algorithms start again. Otherwise, the algorithms do not improve the solution, thus the algorithms stop. Note that inserting and swapping algorithm have the same logic but they are run separately.

The pseudo-code of the proposed modification is given bellow (algorithm \ref{insert}):

\begin{algorithm}[H]
\caption{swapping\_algorithm / inserting\_algorithm(initial\_routing\_configuration, $ \beta$, order\_criteria) }
\label{insert}
\begin{algorithmic}[1]
	
	\STATE routing configuration $\leftarrow$ sorted(initial routing configuration, order\_criteria) 													  
	\STATE stop\_algorithm  $\leftarrow$ 0
	
	\WHILE{ stop\_algorithm = 0}
	\STATE stop\_iter  $\leftarrow$ 0
	\WHILE{ stop\_iter $\ne$ 1}
	\STATE M  $\leftarrow$ compute\_M($p,n$)
	\STATE candidate\_inserted  $\leftarrow$ 0
	
	\WHILE{ candidate\_inserted = 0 and stop\_iter  $\ne$ 1}
	\STATE candidate $\leftarrow$ select candidate from M using $\beta$
	\STATE routing configuration  $\leftarrow$  candidate
	\IF {routing configuration respect constraints}
	\STATE list\_improvements(routing configuration)  $\leftarrow$  routing configuration
	\ELSE
	\STATE remove candidate from M
	\ENDIF
	\IF{ $max(M(\alpha))<0$}
	\STATE stop\_iter  $\leftarrow$ 1	    
	\ENDIF
	\ENDWHILE
	
	\IF {there are no\_improvements}
	\STATE stop\_algorithm  $\leftarrow$ 1
	\ENDIF
	
	\ENDWHILE
	\ENDWHILE
	
\end{algorithmic}

\end{algorithm}

\subsection{Main algorithm}\label{Mainalgorithm}

The proposed metaheuristic has been implement by a main algorithm which incorporates exchange, inserting and swapping algorithms. These three algorithms define local searches which are guided by the metaheuristic under different $\beta$ values.

In this sense, the metaheuristic computes one of the initial solutions detailed in subsection \ref{initialsol}. Once an initial solution is created, the metaheuristic improves it by iterating through the procedure. That is, given an initial solution, the metaheuristic enhances it by computing exchange moves of routes, inserting or swapping customers between routes. Each of these local searches may obtain different improved solutions, thus the metaheuristic chooses the best one and it sets the best improved solution as the new solution. This logic is repeated until a stopping criteria is met. The stopping criteria will be discuss after introducing some concepts. Recall that the local searches incorporates a probabilistic parameter $\beta$ and both inserting and swapping algorithms can order a given solution. In this way, the metaheuristic runs local searches under all possible sorting criteria: decreasing, increasing or no order. 

Let's analize the metaheuristic's behavior under different $\beta$ values. Recall that whether $\beta=1$ local searches must select the best move as candidate, while small $\beta$ values allow local searches to select candidates which do not represents big savings. Let $\beta=1$ and consider an initial solution, $R$, whose cost is noted by $c(R)$. Suppose that $R$ is being enhanced by a local search, for example, swapping algorithm. Remember that this algorithm creates a matrix $M$ which represents all swaps, where its first row represents the best move, the second row represents the second best move, etc. Then the swapping algorithm starts at $R$ and it performs the best swap creating $R_{1}$ such that $c(R_{1}) \leq c(R)$. After this swap, the algorithm may finish because no swap which represents savings can be taken. However, if $\beta<1$ a different move can be taken, for example the second best move. Selecting the second candidate, the algorithm creates a new route $R_{2}$ such that, $c(R_{1}) \leq c(R_{2}) \leq c(R)$. After this move, the algorithm is more likely to find other swap which represents savings. Thus, a second swap can be taken computing a route $R_{3}$ such that $c(R_{3})\leq c(R_{1}) \leq c(R_{2}) \leq c(R)$. Thus, if $\beta = 1$, a local search can stop at a local minimum, while if $\beta <1$ the local search may find better solutions. One can find that this logic is very similar to the one implemented by Lin and Kerninham, which was explained at subsection \ref{MovesInsideRoutes}. Furthermore, if $\beta$ is small enough, the local searches may select candidates which represent losses. Taking these candidates may do not seem good a good idea but it can help to explore different solutions.

The proposed metaheuristic incorporates this consideration by starting to iterate with small $\beta$ values. To test the metaheuristic behavior, first iterations are run with $\beta = 0.6$, allowing the local searches to choose negative moves. Once no improvements are found by local searches, the metaheuristic sets $\beta = 0.8$, in order to find better solutions. Under this $\beta$ value, the local searches may not select negative moves but they do not have to select the best candidate. When no improvements are found under $\beta = 0.8$ the metaheuristic change to $\beta=1$ to refine the final solution. Once no improvements are found, the metaheuristic ends approximating the optimum of the problem by the last found solution, $R^{'}$. A metaheuristic may provide a sufficiently good solution, but it may be improved. One can think that proposed metaheuristic can enhanced $R^{'}$ by setting $\beta<1$ again. That is probably true, however, it is not certain that the probabilistic parameter did not guide the local search to a local minimum. Thus, the metaheuristic must end if $\beta = 1$ and the local search do not improve the solution. These considerations form the stopping criteria. If one wants to obtain a better solution than $R^{'}$, the metaheuristic must be run again starting from one of the initial solutions detailed in subsection \ref{initialsol}. The pseudo-code of the proposed metaheuristic is given at the end of these section (algorithm \ref{main}).


Observe that the proposed metaheuristic runs the local searches individually to evaluate three different moves: exchanges, insertions or swaps. That is, the metaheuristic gives a solution, $R$, to every local search and it chooses the best improved solution, $R^{'}$. What means that $R$ is improved by one kind of move. Lets evaluate how the proposed metaheuristic combines the different moves. Suppose that the metaheuristic is started at a dummy solution and recall that dummy solution's routes only visit one customer. In this routing configuration, the time window constraints are soft constraints, thus the inserting algorithm can reduce the number of routes. Hence, at first iterations, inserting algorithm performs the best improvements. After a few iterations, the routes of the improved solution visit few customers, thus the time windows constraints may allow to perform some insertions. Since the routes visit few customers the exchange algorithm can reduce the routes' cost. Furthermore, the inserting algorithm could has made insertions which guide the metaheuristic local minimum. However, the swapping algorithm can break them up at these iterations. In this situation, the three local searches can improve the actual solution. At last iterations of the metaheuristic, the local searches must improve a routing configuration whose routes visit lot of customers, which implies that time windows constraints are strong constraints. Hence, exchange and swapping algorithms may offer the best improvements. On the other hand, if an elaborated initial solution is considered, every local search have a main role in the metaheuristic. Observe that swapping algorithm can reconfigure the clustered customers if it is needed.

\begin{algorithm}[H]
\caption{Metaheuristc}
\label{main}
\begin{algorithmic}[1]
	\STATE solution $\leftarrow$ initial solution
	\STATE iter $\leftarrow$ 1
	\STATE $\beta_{values} \leftarrow (0.6, 0.8, 1)$          																	  
	\WHILE{ iter	$<$ len(beta)}
	\STATE $\beta \leftarrow \beta_{values}(iter)$
	\STATE no\_improvement  $\leftarrow$ 0
	\WHILE{ no\_impromevement	  $\ne$ 1 }
	\STATE  list(solutions) $ \leftarrow$ inserting\_algorithm(solution, $\beta$, order = decreasing)			
	\STATE  list(solutions) $ \leftarrow$ inserting\_algorithm(solution, $\beta$, order = increasing)			
	\STATE  list(solutions) $ \leftarrow$ swapping\_algorithm(solution, $\beta$)				
	\STATE  list(solutions) $ \leftarrow$ exchange\_algorithm(solution,$\beta$)							
	\STATE  new solution $ \leftarrow$ best( list(solutions))
	\IF{ new solution is better than solution}
	\STATE solution $\leftarrow$ new solution
	\STATE clear (list(solutions)) 
	\ELSE 
	\STATE  no\_improvement $\leftarrow$  1 
	\ENDIF
	\ENDWHILE
	\STATE iter $\leftarrow$ iter + 1 
	\ENDWHILE
	\STATE return (solution)
\end{algorithmic}
\end{algorithm}



\section{Computational results}\label{results}
This section describes experimental results obtained with the proposed metaheuristic, which was coded in Python and run on an $Intel^{\textsuperscript{\textregistered}}$ $Core^{TM}$ i7-8750H at 2.20GHz and 16BG RAM. The metaheuristic was tested with Solomon benchmark problems and at a real agricultural cooperative problem.

\subsection{Solomon benchmark}
Computational results has been conducted to compare the perform of the proposed metaheuristic, which has been tested with 56 VRPTW benchmark problems of Solomon (1987). 

These instances are widely used in the literature. Each problem involves 100 customers, distributed over a square $[0,100]^{2}$ in the plane. Customer locations for a those instances are either generated randomly using an uniform distribution, data sets R1 and R2, clustering customers (data sets C1 and C2) or combining randomly distributed and clustered customers (data sets RC1 and RC2).
Distances are represented by Euclidean distance and speed of all vehicles is assumed to be unity. That is, it takes one unit of time to travel one unit of distance. Distance and time are calculated with double precision and total distance results are rounded to two decimals. Instances and best known solutions were obtained at this \href{https://www.sintef.no/projectweb/top/vrptw/solomon-benchmark/100-customers/}{link}. 

The metaheuristic was executed setting $\beta = (0.6, 0.8, 1)$ and starting from an elaborated initial solution. Tables \ref{TABLE-BKS1}, \ref{TABLE-BKS2}, \ref{TABLE-BKS3} compares the best known solutions and the solutions obtained by the proposed metaheuristic. The metaheuristic was executed starting from a dummy solution with some instances. Its results were similar to the ones obtained starting from an elaborated initial solution, but it was much time-consuming. Thus the whole Solomon data set was executed from an elaborated initial solution.

The metaheuristic offers good results at data sets C1 and C2. Setting $\beta = (0.6, 0.8, 1)$, it reaches the minimum number of routes to 13 data set out of 16 and it has a GAP of 4.22$\%$ . However, the metaheuristic must be executed with different $\beta$ values to get the best results. Section \ref{Robustness} gathers that analysis showing the metaheuristic gets its best results with $\beta = (0.2, 0.8, 1)$. Under that $\beta $ value the metaheuristic reaches the minim number of routes to all data sets and it has a GAP of 1.62$\%$. Results are gathered in the table bellow (\ref{BKS_soloutionC})

\clearpage

\input{pandas.tex}

\input{best_solutionC.tex}


\subsection{Agricultural cooperative}\label{results-AIRA}

This experiment considers a problem faced on (\cite{Balbina}) by a hybrid heuristic algorithm. This problem aims to minimise transportation costs of an agricultural cooperative.
The cooperative is formed by 15000 farmers located in Galicia, a region of Spain. Farmers demand different kinds of food from the cooperative once or twice a month. Farmer's demand have time windows. Orders can be urgent, which implies that they must supplied the same day.
Furthermore, the cooperative has a heterogeneous fleet of trucks which cannot travel more than a given number of kilometers per day. Trucks can carry food in their hoppers, which have different capacity. Furthermore drivers are paid in terms of distance traveled and load. 

This problem can be modeled by a incapacitated vehicle problem with time windows and heterogeneous fleet thus it can be faced by the proposed algorithm, which will try to minimize the number of routes and maximize truck's load. Different data sets are considered at \cite{Balbina}: a fictitious example, a small instance of real data and two instances of real data which include demands of two days.

\subsubsection{Fictitious example}

This example considers a fleet of two trucks: a small truck with two hoppers that can hold up to four and three tonnes of feed and a large truck with three hoppers, whose capacities are five, four and four tonnes. The first truck can not carry more than 6 tonnes and the large one can carry up to 20 tonnes at a time. These trucks must supply with one type of feed six farmers located in Ourense, Begonte, Friol, Sarria, A Estrada and Forcarei. Lets suppose trucks can perform a route per day. Tables \ref{demand1} and \ref{distance1} provide the parameters of the problem while traveling costs involve the following parameters (\cite{Balbina}):
\begin{itemize}
\item Maximum distance for trucks: 600 km.
\item Unloading cost: 2 euros per delivery.
\item Fixed transport cost: 1 euro per tonne carried.
\item Variable transport cost: 
\subitem Route traveling up to 100 km: 0.5 euros per km per tonne carried.
\subitem Route traveling up to 200 km: 0.75 euros per km per tonne carried.
\subitem Route traveling up to 300 km: 1 euros per km per tonne carried.
\end{itemize}

\begin{table}[H]
\centering
\begin{tabular}{c| c c c c c}
	\hline 
	%	\centering		
	Tonnes  	& Feed 1 & Feed 2   & Feed 3   &  Feed 4  &  Days left to deliver \\
	\hline 
	Ourense    	& & & 4.5 & & 1   \\
	Begonte  	& 4 & & & & 1    \\
	Friol    	& & 3 & & & 1    \\
	Sarria  	& & & & 4 & 3    \\
	A Estrada 	& & & & 3.5&  1  \\
	Forcarei	& 2.5 & & & &  2 \\
	\hline 
\end{tabular}

\caption{Farmers' demand.}
\label{demand1}
\end{table}\

\begin{table}[H]
\centering
\begin{tabular}{c| c c c c c c c}
	\hline 
	%	\centering		
	km/min  	& Coop & Ourense  & Begonte   &  Friol  &  Sarria   & A Estrada & Forcarei\\
	\hline 
	Coop 		& 	0  & 50/47   &  61/60    &  44/41  &  46/46    &  85/69   & 70/67 \\
	Ourense    	& 	   & 0/0     &  111/104  &  93/86  &  78/77    &  96/62   & 81/60 \\
	Begonte  	& 	   &         &  0/0      &  19/20  &  56/44    &  116/97  & 156/105 \\
	Friol    	& 	   &         &           &  0/0    &  57/55    &  103/90  & 92/89 \\
	Sarria  	&	   &         &           &         &  0/0      &  144/115 & 129/113 \\
	A Estrada 	&	   &         &           &         &           &  0/0     & 20/17 \\
	Forcarei	&	   &         &           &         &           &          & 0/ 0 \\
	\hline 
\end{tabular} \
\caption{Distances and traveling times between pairs of stockbreeders and depot.}
\label{distance1}
\end{table}\

The following solution is obtained after execute the proposed metaheuristic one minute:

\begin{itemize}
\item The small truck starts its route at depot, goes to Begonte, Sarria and goes back to the depot.
\item The big truck starts its route at depot, goes to Ourense, Forcarei, A Estrada and goes back to the depot.
\item The farmer from Sarria is not visited the first day.
\end{itemize}

This routing configuration satisfies cooperative's requirements offering solution 456 km.

\subsubsection{Small example}

This example considers a fleet of two trucks with five hoppers that can contain up to 3, 3.7, 3.8, 3.7 and 3 tonnes. Trucks can not carry more than 11.6 tonnes and just can perform a route per day. These trucks must supply, with one type of feed, five farmers with urgent orders of one kind of food. Moreover, both trucks can visit all customers. Table \ref{demand2} shows demand and urgency.


\begin{table}[H]
\centering
\begin{tabular}{c| c c }
	\hline 
	%	\centering		
	Tonnes  	& Feed 1 & Days left to deliver \\
	\hline 
	Farmer 1 &  3.3   & 1	\\
	Farmer 2 &  2.951 & 1	\\
	Farmer 3 &  3.003 & 1 \\
	Farmer 4 &  3.016 & 1	\\
	Farmer 5 &  2.496 & 1 \\
	\hline 
\end{tabular}
\caption{Farmers' demand.}
\label{demand2}
\end{table}\


The following solution is obtained after execute the proposed metaheuristic one minute minimizing the travel cost:

\begin{itemize}
\item First truck starts its route at depot, goes to farmer 1, farmer 4 and goes back to the depot.
\item Second truck starts its route at depot, goes to farmer 2, farmer 3, farmer 5 and goes back to the depot.

\end{itemize}

This routing configuration satisfies cooperative's requirements offering solution 221 km.


\subsubsection{Real examples}

This subsection considers a fleet of two different trucks with five hoppers. The maximum capacity of the hoppers of one truck are 3, 3, 1.7 4.5 and 3 tonnes, while other can contain up to 3, 3.7, 3.8, 3.7 and 3 tonnes. Trucks can not carry more than 15.3 tonnes. Three different sets of orders are considered in this section, which contains demands of 17, 19 and 36 farmers. To supply 36 farmers, fleet is doubled. Table \ref{distancereal} provide an overview of the obtained solutions.


\begin{table}[H]
\centering
\begin{tabular}{c| c c c c}
	\hline 
	%	\centering		
	Data	&	Distance (km)	&	N\textordmasculine routes & N\textordmasculine truck & Time(s)	\\
	\hline
	17 farmers	&	492	&	9	&	2&	64\\
	19 farmers	&	385	&	10	&	2&	164\\
	36 farmers	&	922	&	16	&	4&	1419 \\
	\hline 
\end{tabular} \
\caption{Results real instances.}
\label{distancereal}
\end{table}\


\clearpage

\section{Robustness}\label{Robustness}

Robustness is a desirable property of local search algorithms. An algorithm is robust if it performs well on large classes of problems with the same parameter configuration (\cite{Bent}). 

In order to analyze the metaheuristic's behavior, it was executed to solve Solomon's C1 and C2 instances. It was initialized at an elaborated initial solution and executed with different $\beta$ values, as mean to analyze its behavior under different probabilistic configuration. The first execution corresponds to $\beta = (1)$, which does not introduce random sampling. Second execution corresponds to $\beta = (0.8, 1)$, which allows the metaheuristics to choose one of the best moves. This execution finally sets up $\beta = 1$ to refine the solution. On the contrary, the last execution to $\beta = (0.2, 1)$, which allows the metaheuristics to choose any moves, including the worst moves. The other executions varies $\beta$ values from small values to large ones.

Tables \ref{solomon_beta_values} and\ref{solomon_beta_values2} gather the results of these executions. The metaheuristic performs its best results when $\beta = (0.2, 0.8, 1)$ to both C1 and C2 instances, that is, when then algorithm is randomized. It always reaches the minimum number of trucks and the GAP average to C1 instances is 2.13$\%$ and to C1 instances is 0.85$\%$. The average GAP between all execution is 4.04$\%$ to C1 instances and 4.10$\%$ to C2 instances. Thus the metaheuristic performs well on both data set with the same parameter configuration. 

\input{pandas_betta1.tex}
\clearpage
\input{pandas_betta2.tex}
% \input{pandas_betta3.tex}

To conclude whether the metaheuristic is robust the agricultural cooperative data set were analyzed. To perform this analysis, the metaheuristic was executed under the same conditions as the previous execution. That is, it was initialized at an elaborated initial solution and executed with different $\beta$ values.

Tables \ref{robustezAira1}, \ref{robustezAira2} and \ref{robustezAira3} provide the distance, number of routes and number of trucks of the obtained solutions by different beta values. All tables show that the metaheuristic offers good solutions when $\beta = (0.6, 0.8, 1)$. Moreover, the best solution of two out three instances was found when $\beta = (0.2, 0.8, 1)$.

After these experimental results one can say that the metaheuristic seems to be robust.

\begin{table}[H]
	\centering
	\begin{tabular}{c| c c c c c}
		\hline 		
		$\beta$		&	Distance	&	N\textordmasculine routes & N\textordmasculine truck & Time (s) \\
		\hline 	
		(1, 1, 1)	    &   385	  &   8   &	2	&	64\\
		(0.8, 1)		&   385	  &   8   &	2	&	72\\
		(0.6, 0.8, 1)	&   385	  &   8   &	2	&	101\\
		(0.2, 0.6, 0.8, 1)	&   403	  &   9   &	2	&	146\\
		(0.2, 0.8, 1)	&   385	  &   8   &	2	&	103	\\
		(0.2, 1)		&   385	  &   8   &	2	&	85\\
		\hline 
	\end{tabular} \
	\caption{Results for minimizing distance 17 farmer data set.}
	\label{robustezAira1}
\end{table}


\begin{table}[H]
	\centering
	\begin{tabular}{c| c c c c c}
		\hline 		
		$\beta$		&	Distance	&	N\textordmasculine routes & N\textordmasculine truck & Time (s)\\
		\hline 	
		(1, 1, 1)	    &   497	  &   11   &	2&	88\\
		(0.8, 1)		&   497	  &   11   &	2&	121\\
		(0.6, 0.8, 1)	&   492	  &   10   &	2&	164\\
		(0.2, 0.6, 0.8, 1)	&   493	  &   10   &	2&	237\\
		(0.2, 0.8, 1)	&   492	  &   10   &	2&	203\\
		(0.2, 1)		&   508	  &   11   &	2&	146\\
		\hline 
	\end{tabular} \
	\caption{Results for minimizing distance 19 farmer data set.}
	\label{robustezAira2}
\end{table}


\begin{table}[H]
	\centering
	\begin{tabular}{c| c c c c c}
		\hline 		
		$\beta$		&	Distance	&	N\textordmasculine routes & N\textordmasculine truck & Time (s)\\
		\hline 	
		(1, 1, 1)	    &   998	  &  15  &	4&	858\\
		(0.8, 1)		&   982	  &   16   &	4&	1421\\
		(0.6, 0.8, 1)	&   922	  &   16   &	4&	1419\\
		(0.2, 0.6, 0.8, 1)	&   982	  &   16   &	4&	1885\\
		(0.2, 0.8, 1)	&   982	  &   16   &	4&	1642\\
		(0.2, 1)		&   956	  &   16   &	4&	1337\\
		\hline 
	\end{tabular} \
	\caption{Results for minimizing distance 36 farmer data set.}
	\label{robustezAira3}
\end{table}


Moreover the convergence of the metaheuristic was analyzed. To perform that study one instance of each data set was selected: Solomon instance C103, Solomon instance C203 and the 19 farmer from the agricultural cooperative problem. Then the metaheuristic was initialized at an elaborated initial solution and executed with different $\beta$ values. Recall that the metaheuristic improves the initial solution in terms of distance at each iteration. This improvement was saved to analyze its convergence. 


Figure \ref{robustedSolomonC103} shows the distance improvement of the Solomon C103 instance in terms of distance. The metaheuristic performs a big improvement at first iterations with all $\beta$ values. The metaheuristc reach a distance between 1060 and 850 distance units at these first iterations. Finally it makes small improvements until it finishes, finding a minimum distance between 1000 and 840. Moreover the number of iteration varies from 6 to 10, which is not a big variation. The metaheuristic has a similar trend with all $\beta$ values

\begin{figure}[H]
	\centering
	\includegraphics[width=.3\textwidth]{./img/C103_km_newplot (1)}\hfill
	\includegraphics[width=.3\textwidth]{./img/C103_km_newplot (2)}\hfill
	\includegraphics[width=.3\textwidth]{./img/C103_km_newplot (3)}
	\\
	\includegraphics[width=.3\textwidth]{./img/C103_km_newplot (4)}\hfill
	\includegraphics[width=.3\textwidth]{./img/C103_km_newplot (5)}\hfill
	\includegraphics[width=.3\textwidth]{./img/C103_km_newplot (6)}
	\caption{Distance improvement at each iteration of Solomon C103 instance}
	\label{robustedSolomonC103}
\end{figure}

Figure \ref{robustedSolomonC1032} shows the number of routes decrease of the Solomon C103 instance. At most instances, the metaheuristic reaches the minimum number of trucks at first iterations with all $\beta$ values. However, when $\beta = (0.2, 0.6, 0.8, 1)$ the metaheuristc do not reduces the number of routes. Recall that the best results were found with $\beta = (0.2, 0.8, 1)$, when the metaheuristic finds the minimum number of routes at its first iteration.

\begin{figure}[H]
	\centering
	\includegraphics[width=.3\textwidth]{./img/C103_route_newplot (1)}\hfill
	\includegraphics[width=.3\textwidth]{./img/C103_route_newplot (2)}\hfill
	\includegraphics[width=.3\textwidth]{./img/C103_route_newplot (3)}
	\\
	\includegraphics[width=.3\textwidth]{./img/C103_route_newplot (4)}\hfill
	\includegraphics[width=.3\textwidth]{./img/C103_route_newplot (5)}\hfill
	\includegraphics[width=.3\textwidth]{./img/C103_route_newplot (6)}
	\caption{Number of routes improvement at each iteration of Solomon C103 instance}
	\label{robustedSolomonC1032}
\end{figure}



Figure \ref{robustedSolomonC203} shows the distance improvement of the Solomon C203 instance in terms of distance. As the previous example, the metaheuristic performs a big improvement at first iterations with all $\beta$ values. The metaheuristc reach a distance between 1000 and 800 distance units at these first iterations. Finally it makes small improvements until it finishes, finding a minimum distance between 950 and 650. Moreover the number of iteration varies from 6 to 11, which is not a big variation. That implies that the behavior of the metaheuristic is similar in terms of convergence and number of iterations with C103 and C203 instances. It also shows a similar trend with all $\beta$ values

\begin{figure}[H]
	\centering
	\includegraphics[width=.3\textwidth]{./img/C203_km_newplot (1)}\hfill
	\includegraphics[width=.3\textwidth]{./img/C203_km_newplot (2)}\hfill
	\includegraphics[width=.3\textwidth]{./img/C203_km_newplot (3)}
	\\
	\includegraphics[width=.3\textwidth]{./img/C103_km_newplot (4)}\hfill
	\includegraphics[width=.3\textwidth]{./img/C103_km_newplot (5)}\hfill
	\includegraphics[width=.3\textwidth]{./img/C103_km_newplot (6)}
	\caption{Distance improvement at each iteration of Solomon C103 instance}
	\label{robustedSolomonC203}
\end{figure}

Figure \ref{robustedSolomonC2032} shows the number of routes decrease of the Solomon C203 instance. At most instances, the metaheuristic reaches the minimum number of at first iterations with all $\beta$ values. However, when $\beta = (0.8, 1)$ the metaheuristc do not reduces the number of routes. Recall that the best results were found with $\beta = (0.2, 0.8, 1)$, when the metaheuristic finds the minimum number of routes at its fifth iteration.

\begin{figure}[H]
	\centering
	\includegraphics[width=.3\textwidth]{./img/C203_distance_newplot (1)}\hfill
	\includegraphics[width=.3\textwidth]{./img/C203_distance_newplot (2)}\hfill
	\includegraphics[width=.3\textwidth]{./img/C203_distance_newplot (3)}
	\\
	\includegraphics[width=.3\textwidth]{./img/C203_distance_newplot (4)}\hfill
	\includegraphics[width=.3\textwidth]{./img/C203_distance_newplot (5)}\hfill
	\includegraphics[width=.3\textwidth]{./img/C203_distance_newplot (6)}
	\caption{Number of routes improvement at each iteration of Solomon C103 instance}
	\label{robustedSolomonC2032}
\end{figure}

Finally, figure \ref{robustedAira3} represents how the metaheuristic improves the initial solution at each iteration to 19 farmer instance. s in the previous examples, the metaheuristic performs a big improvement at first iteration under all $\beta$ values. The initial solution has over 700 km and the improved solution at the first iteration has over 500km. Finally the metaheuristic makes small improvements until it finishes. Note that it also has a similar trend at all $\beta$ values.

Results are similar in terms of distance and convergence, that means that the metaheuristic is robust at different $\beta$ values.

\begin{figure}[H]
	\centering
	\includegraphics[width=.3\textwidth]{./img/AIRA newplot (1)}\hfill
	\includegraphics[width=.3\textwidth]{./img/AIRA newplot (2)}\hfill
	\includegraphics[width=.3\textwidth]{./img/AIRA newplot (3)}
	\\
	\includegraphics[width=.3\textwidth]{./img/AIRA newplot (4)}\hfill
	\includegraphics[width=.3\textwidth]{./img/AIRA newplot (5)}\hfill
	\includegraphics[width=.3\textwidth]{./img/AIRA newplot (6)}
	\caption{Distance improvement at each iteration of 19 farmer instance}
	\label{robustedAira3}
\end{figure}

To sum up, the metaheuristic has proved to perform well on different data sets with the same parameter configuration. By (\cite{Bent}) one can say that the metaheuristic seems to be robust. Furthermore it has similar behavior in terms of number of iterations and convergence.

